{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxmTDTQ1abln"
      },
      "source": [
        "# **Method - 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qIPIPSMuQZg5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zqfUzsnFSNLC"
      },
      "outputs": [],
      "source": [
        "project_path = \"/content/drive/MyDrive/transformertranslator/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ywBa6S8aR7Kg"
      },
      "outputs": [],
      "source": [
        "# read phrases from english_telugu_data.txt file\n",
        "english_sentances = []\n",
        "telugu_sentances = []\n",
        "with open(project_path+\"english_telugu_data.txt\", mode='rt', encoding='utf-8') as fp:\n",
        "    for line in fp.readlines():\n",
        "        eng_tel = line.split(\"++++$++++\")\n",
        "        english_sentances.append(eng_tel[0])\n",
        "        telugu_sentances.append(eng_tel[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e0OFYx2ISFM1"
      },
      "outputs": [],
      "source": [
        "data = pd.DataFrame({\"english_sentances\":english_sentances,\"telugu_sentances\":telugu_sentances})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Y_uBhVjtV4v3",
        "outputId": "ea55a0d5-65be-4639-aa66-bb855cd752d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   english_sentances  \\\n",
              "0                                 His legs are long.   \n",
              "1                Who taught Tom how to speak French?   \n",
              "2                       I swim in the sea every day.   \n",
              "3  Tom popped into the supermarket on his way hom...   \n",
              "4                             Smoke filled the room.   \n",
              "\n",
              "                                    telugu_sentances  \n",
              "0                     అతని కాళ్ళు పొడవుగా ఉన్నాయి.\\n  \n",
              "1          టామ్ ఫ్రెంచ్ మాట్లాడటం ఎలా నేర్పించారు?\\n  \n",
              "2            నేను ప్రతి రోజు సముద్రంలో ఈత కొడతాను.\\n  \n",
              "3  టామ్ కొంచెం పాలు కొనడానికి ఇంటికి వెళ్ళేటప్పుడ...  \n",
              "4                              పొగ గదిని నింపింది.\\n  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2364ac2d-8ebe-43c7-8b0f-1e6afb67423a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentances</th>\n",
              "      <th>telugu_sentances</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>His legs are long.</td>\n",
              "      <td>అతని కాళ్ళు పొడవుగా ఉన్నాయి.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who taught Tom how to speak French?</td>\n",
              "      <td>టామ్ ఫ్రెంచ్ మాట్లాడటం ఎలా నేర్పించారు?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I swim in the sea every day.</td>\n",
              "      <td>నేను ప్రతి రోజు సముద్రంలో ఈత కొడతాను.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tom popped into the supermarket on his way hom...</td>\n",
              "      <td>టామ్ కొంచెం పాలు కొనడానికి ఇంటికి వెళ్ళేటప్పుడ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Smoke filled the room.</td>\n",
              "      <td>పొగ గదిని నింపింది.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2364ac2d-8ebe-43c7-8b0f-1e6afb67423a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2364ac2d-8ebe-43c7-8b0f-1e6afb67423a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2364ac2d-8ebe-43c7-8b0f-1e6afb67423a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-605ee4cb-586d-47ba-b514-e3e6f1991fcb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-605ee4cb-586d-47ba-b514-e3e6f1991fcb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-605ee4cb-586d-47ba-b514-e3e6f1991fcb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AEML9o71Lhlo",
        "outputId": "1092d7b9-3afd-48de-e66f-bed51403263d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        english_sentances  \\\n",
              "155993  The hand gesture, called \"Abhaya Mudra,\" repre...   \n",
              "155994  It symbolizes the act of listening deeply to t...   \n",
              "155995  It symbolizes the Bodhisattva's vow to listen ...   \n",
              "155996  Avalokiteshvara's hand gestures convey various...   \n",
              "155997  Buddhist teachings inspire art by conveying pr...   \n",
              "\n",
              "                                         telugu_sentances  \n",
              "155993  \"అభయ ముద్ర,\" అని పిలుస్తారు, బాధితులకు ఆత్మవిశ...  \n",
              "155994  అది ప్రజల దుఃఖానికి ఆత్మగా వినియోగం చేస్తుంది ...  \n",
              "155995  ఇది బోధిసత్త్వ ప్రతిజ్ఞను సూచిస్తుంది ప్రపంచాన...  \n",
              "155996  అవలోకితేశ్వర చేతుల చిహ్నాలు వివిధ అర్థాలను సూచ...  \n",
              "155997  బౌద్ధ ఉపదేశాలు ఆళ్లలో గంభీరమైన ఆధ్యాత్మిక అంశా...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-343e7bfd-d93a-4849-8305-51eb5a65e08b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentances</th>\n",
              "      <th>telugu_sentances</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>155993</th>\n",
              "      <td>The hand gesture, called \"Abhaya Mudra,\" repre...</td>\n",
              "      <td>\"అభయ ముద్ర,\" అని పిలుస్తారు, బాధితులకు ఆత్మవిశ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155994</th>\n",
              "      <td>It symbolizes the act of listening deeply to t...</td>\n",
              "      <td>అది ప్రజల దుఃఖానికి ఆత్మగా వినియోగం చేస్తుంది ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155995</th>\n",
              "      <td>It symbolizes the Bodhisattva's vow to listen ...</td>\n",
              "      <td>ఇది బోధిసత్త్వ ప్రతిజ్ఞను సూచిస్తుంది ప్రపంచాన...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155996</th>\n",
              "      <td>Avalokiteshvara's hand gestures convey various...</td>\n",
              "      <td>అవలోకితేశ్వర చేతుల చిహ్నాలు వివిధ అర్థాలను సూచ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155997</th>\n",
              "      <td>Buddhist teachings inspire art by conveying pr...</td>\n",
              "      <td>బౌద్ధ ఉపదేశాలు ఆళ్లలో గంభీరమైన ఆధ్యాత్మిక అంశా...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-343e7bfd-d93a-4849-8305-51eb5a65e08b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-343e7bfd-d93a-4849-8305-51eb5a65e08b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-343e7bfd-d93a-4849-8305-51eb5a65e08b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a1c32308-680c-43d6-8862-278f39375a83\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a1c32308-680c-43d6-8862-278f39375a83')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a1c32308-680c-43d6-8862-278f39375a83 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"english_sentances\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"It symbolizes the act of listening deeply to the suffering of the world with compassion and offering assistance to alleviate it.\",\n          \"Buddhist teachings inspire art by conveying profound spiritual ideas, values, and narratives that artists interpret and express through their creations.\",\n          \"It symbolizes the Bodhisattva's vow to listen to the cries of the world and respond with compassion and assistance.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"telugu_sentances\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u0c05\\u0c26\\u0c3f \\u0c2a\\u0c4d\\u0c30\\u0c1c\\u0c32 \\u0c26\\u0c41\\u0c03\\u0c16\\u0c3e\\u0c28\\u0c3f\\u0c15\\u0c3f \\u0c06\\u0c24\\u0c4d\\u0c2e\\u0c17\\u0c3e \\u0c35\\u0c3f\\u0c28\\u0c3f\\u0c2f\\u0c4b\\u0c17\\u0c02 \\u0c1a\\u0c47\\u0c38\\u0c4d\\u0c24\\u0c41\\u0c02\\u0c26\\u0c3f \\u0c2e\\u0c30\\u0c3f\\u0c2f\\u0c41 \\u0c06\\u0c24\\u0c4d\\u0c2e\\u0c39\\u0c24\\u0c4d\\u0c2f\\u0c28\\u0c41 \\u0c24\\u0c17\\u0c4d\\u0c17\\u0c3f\\u0c02\\u0c1a\\u0c21\\u0c3e\\u0c28\\u0c3f\\u0c15\\u0c3f \\u0c38\\u0c39\\u0c3e\\u0c2f\\u0c02 \\u0c1a\\u0c47\\u0c38\\u0c4d\\u0c24\\u0c41\\u0c02\\u0c26\\u0c3f.\\n\",\n          \"\\u0c2c\\u0c4c\\u0c26\\u0c4d\\u0c27 \\u0c09\\u0c2a\\u0c26\\u0c47\\u0c36\\u0c3e\\u0c32\\u0c41 \\u0c06\\u0c33\\u0c4d\\u0c32\\u0c32\\u0c4b \\u0c17\\u0c02\\u0c2d\\u0c40\\u0c30\\u0c2e\\u0c48\\u0c28 \\u0c06\\u0c27\\u0c4d\\u0c2f\\u0c3e\\u0c24\\u0c4d\\u0c2e\\u0c3f\\u0c15 \\u0c05\\u0c02\\u0c36\\u0c3e\\u0c32\\u0c28\\u0c41, \\u0c35\\u0c3f\\u0c32\\u0c41\\u0c35\\u0c32\\u0c28\\u0c41, \\u0c2e\\u0c30\\u0c3f\\u0c2f\\u0c41 \\u0c15\\u0c25\\u0c32\\u0c28\\u0c41 \\u0c2a\\u0c4d\\u0c30\\u0c15\\u0c1f\\u0c3f\\u0c02\\u0c1a\\u0c47\\u0c02\\u0c26\\u0c41\\u0c15\\u0c41 \\u0c15\\u0c33\\u0c3e\\u0c15\\u0c3e\\u0c30\\u0c41\\u0c32\\u0c41 \\u0c05\\u0c28\\u0c41\\u0c35\\u0c26\\u0c3f\\u0c38\\u0c4d\\u0c24\\u0c3e\\u0c30\\u0c41 \\u0c2e\\u0c30\\u0c3f\\u0c2f\\u0c41 \\u0c05\\u0c35\\u0c3f \\u0c05\\u0c35\\u0c3f\\u0c37\\u0c4d\\u0c15\\u0c30\\u0c3f\\u0c38\\u0c4d\\u0c24\\u0c41\\u0c28\\u0c4d\\u0c28\\u0c3e\\u0c30\\u0c41.\\n\",\n          \"\\u0c07\\u0c26\\u0c3f \\u0c2c\\u0c4b\\u0c27\\u0c3f\\u0c38\\u0c24\\u0c4d\\u0c24\\u0c4d\\u0c35 \\u0c2a\\u0c4d\\u0c30\\u0c24\\u0c3f\\u0c1c\\u0c4d\\u0c1e\\u0c28\\u0c41 \\u0c38\\u0c42\\u0c1a\\u0c3f\\u0c38\\u0c4d\\u0c24\\u0c41\\u0c02\\u0c26\\u0c3f \\u0c2a\\u0c4d\\u0c30\\u0c2a\\u0c02\\u0c1a\\u0c3e\\u0c28\\u0c4d\\u0c28\\u0c3f \\u0c35\\u0c3f\\u0c28\\u0c3f\\u0c2f\\u0c4b\\u0c17\\u0c02 \\u0c1a\\u0c47\\u0c38\\u0c4d\\u0c24\\u0c41\\u0c02\\u0c21\\u0c1f\\u0c3e\\u0c28\\u0c3f\\u0c15\\u0c3f \\u0c39\\u0c43\\u0c26\\u0c2f\\u0c3e\\u0c32\\u0c28\\u0c41 \\u0c35\\u0c3f\\u0c28\\u0c3f\\u0c2f\\u0c4b\\u0c17\\u0c3f\\u0c02\\u0c1a\\u0c3e\\u0c32\\u0c28\\u0c3f.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9P2pv-ZV9Kj",
        "outputId": "f41a80aa-49b2-4b75-8730-ac462e37d7e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(155998, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "690ufcsjV8_i",
        "outputId": "7085cffe-92b4-4c71-f66c-1068186450b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(155998, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HLYb2GNoV870"
      },
      "outputs": [],
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "b4UKdK5qV84B"
      },
      "outputs": [],
      "source": [
        "# clean english sentances\n",
        "def clean_eng(text):\n",
        "    # Lowercase all characters\n",
        "    text = text.lower()\n",
        "    # map contractions\n",
        "    text = ' '.join([contraction_mapping[w] if w in contraction_mapping else w for w in text.split(\" \")])\n",
        "    # Remove quotes\n",
        "    text = re.sub(\"'\", '', text)\n",
        "    # Remove all the special characters\n",
        "    exclude = set(string.punctuation) # Set of all special characters\n",
        "    text = ''.join([c for c in text if c not in exclude])\n",
        "    # Remove all numbers from text\n",
        "    remove_digits = str.maketrans('', '', digits)\n",
        "    text = text.translate(remove_digits)\n",
        "    # Remove extra spaces\n",
        "    text= text.strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1F_8aq-YV80H"
      },
      "outputs": [],
      "source": [
        "# clean telugu sentances\n",
        "def clean_tel(text):\n",
        "    # Lowercase all characters\n",
        "    text = text.lower()\n",
        "    # Remove quotes\n",
        "    text = re.sub(\"'\", '', text)\n",
        "    # Remove all the special characters\n",
        "    exclude = set(string.punctuation) # Set of all special characters\n",
        "    text = ''.join([c for c in text if c not in exclude])\n",
        "    # Remove all numbers from text\n",
        "    remove_digits = str.maketrans('', '', digits)\n",
        "    text = text.translate(remove_digits)\n",
        "    # Remove Telugu numbers from text\n",
        "    text = re.sub(\"[౦౧౨౩౪౫౬౭౮౯]\", '', text)\n",
        "    # Remove extra spaces\n",
        "    text= text.strip()\n",
        "    text = 'START_ '+ text + ' _END'\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rG1oO8MGV8PH"
      },
      "outputs": [],
      "source": [
        "# clean text\n",
        "data_df = data.copy()\n",
        "data_df[\"english_sentances\"] = data_df[\"english_sentances\"] .apply(lambda x: clean_eng(x))\n",
        "data_df[\"telugu_sentances\"] = data_df[\"telugu_sentances\"] .apply(lambda x: clean_tel(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0AGwcIYGY3xS"
      },
      "outputs": [],
      "source": [
        "# Vocabulary of English\n",
        "all_eng_words=set()\n",
        "for eng in data_df.english_sentances:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "\n",
        "# Vocabulary of French\n",
        "all_telugu_words=set()\n",
        "for tel in data_df.telugu_sentances:\n",
        "    for word in tel.split():\n",
        "        if word not in all_telugu_words:\n",
        "            all_telugu_words.add(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mRmYtR8Y48-",
        "outputId": "ceb4eeae-b5db-4ec0-f9ab-09214811f466"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Max Length of source sequence\n",
        "lenght_list=[]\n",
        "for l in data_df.english_sentances:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_src = np.max(lenght_list)\n",
        "max_length_src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPkIiAynY45h",
        "outputId": "ba0a47e5-1a64-47b4-d793-60963b4fd873"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Max Length of target sequence\n",
        "lenght_list=[]\n",
        "for l in data_df.telugu_sentances:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_tar = np.max(lenght_list)\n",
        "max_length_tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO9gznN7Y40p",
        "outputId": "a95cd917-f2ce-4405-f7db-8b3a0148509d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14027, 38960)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_telugu_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_telugu_words)\n",
        "num_encoder_tokens, num_decoder_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "makWgWSaY4wx",
        "outputId": "d8426d35-1b93-4b63-d452-6b6c67dcb085"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38961"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "num_decoder_tokens += 1 # For zero padding\n",
        "num_decoder_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RYq7A56BY4s_"
      },
      "outputs": [],
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EhhHVmytY4o6"
      },
      "outputs": [],
      "source": [
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Lj9j9GujY4kv",
        "outputId": "02e99ec8-a7d5-4676-d52c-27761b3761f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        english_sentances  \\\n",
              "76414                             she ignored him all day   \n",
              "89802                                    i had to go back   \n",
              "139684                                 tom turned to mary   \n",
              "88529                            the pain was intolerable   \n",
              "31043   i do not know how long it takes to get to bost...   \n",
              "39289        the enemy gave in without further resistance   \n",
              "151642             who can tell me how a light bulb works   \n",
              "15412                             there was a traffic jam   \n",
              "90098                                           i am warm   \n",
              "66642                 how long are you going to stay here   \n",
              "\n",
              "                                         telugu_sentances  \n",
              "76414        START_ ఆమె రోజంతా అతన్ని పట్టించుకోలేదు _END  \n",
              "89802          START_ నేను తిరిగి వెళ్ళవలసి వచ్చింది _END  \n",
              "139684               START_ టామ్ మేరీ వైపు తిరిగింది _END  \n",
              "88529                      START_ నొప్పి భరించలేనిది _END  \n",
              "31043   START_ ఇక్కడి నుండి బోస్టన్‌కు వెళ్లడానికి ఎంత...  \n",
              "39289   START_ మరింత ప్రతిఘటన లేకుండా శత్రువు ఇచ్చాడు ...  \n",
              "151642  START_ లైట్ బల్బ్ ఎలా పనిచేస్తుందో నాకు ఎవరు చ...  \n",
              "15412                      START_ ట్రాఫిక్ జామ్ ఉంది _END  \n",
              "90098                    START_ నేను వెచ్చగా ఉన్నాను _END  \n",
              "66642       START_ మీరు ఎంతకాలం ఇక్కడే ఉండబోతున్నారు _END  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74366b80-d6f5-4a67-ab5b-a6115d5a58d2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentances</th>\n",
              "      <th>telugu_sentances</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76414</th>\n",
              "      <td>she ignored him all day</td>\n",
              "      <td>START_ ఆమె రోజంతా అతన్ని పట్టించుకోలేదు _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89802</th>\n",
              "      <td>i had to go back</td>\n",
              "      <td>START_ నేను తిరిగి వెళ్ళవలసి వచ్చింది _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139684</th>\n",
              "      <td>tom turned to mary</td>\n",
              "      <td>START_ టామ్ మేరీ వైపు తిరిగింది _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88529</th>\n",
              "      <td>the pain was intolerable</td>\n",
              "      <td>START_ నొప్పి భరించలేనిది _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31043</th>\n",
              "      <td>i do not know how long it takes to get to bost...</td>\n",
              "      <td>START_ ఇక్కడి నుండి బోస్టన్‌కు వెళ్లడానికి ఎంత...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39289</th>\n",
              "      <td>the enemy gave in without further resistance</td>\n",
              "      <td>START_ మరింత ప్రతిఘటన లేకుండా శత్రువు ఇచ్చాడు ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151642</th>\n",
              "      <td>who can tell me how a light bulb works</td>\n",
              "      <td>START_ లైట్ బల్బ్ ఎలా పనిచేస్తుందో నాకు ఎవరు చ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15412</th>\n",
              "      <td>there was a traffic jam</td>\n",
              "      <td>START_ ట్రాఫిక్ జామ్ ఉంది _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90098</th>\n",
              "      <td>i am warm</td>\n",
              "      <td>START_ నేను వెచ్చగా ఉన్నాను _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66642</th>\n",
              "      <td>how long are you going to stay here</td>\n",
              "      <td>START_ మీరు ఎంతకాలం ఇక్కడే ఉండబోతున్నారు _END</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74366b80-d6f5-4a67-ab5b-a6115d5a58d2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-74366b80-d6f5-4a67-ab5b-a6115d5a58d2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-74366b80-d6f5-4a67-ab5b-a6115d5a58d2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0dcb4a45-fef9-4486-80f3-924c804cad5a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0dcb4a45-fef9-4486-80f3-924c804cad5a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0dcb4a45-fef9-4486-80f3-924c804cad5a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_df"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "data_df = shuffle(data_df)\n",
        "data_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDf4ofWSY_8r",
        "outputId": "e06de849-75be-43fb-a153-762f91e3593c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((140398,), (15600,))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Train - Test Split\n",
        "X, y = data_df.english_sentances, data_df.telugu_sentances\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "YpG3SUimY_5s"
      },
      "outputs": [],
      "source": [
        "X_train.to_pickle(project_path+'X_train.pkl')\n",
        "X_test.to_pickle(project_path+'X_test.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gz7R2mkjY_2m"
      },
      "outputs": [],
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8LPCZ9X-Y_zf"
      },
      "outputs": [],
      "source": [
        "latent_dim = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "y0x1Rt4CY_wR"
      },
      "outputs": [],
      "source": [
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6zPxtLGGY_s6"
      },
      "outputs": [],
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rQS3n0yUY_pe"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RPprDwk-Y4g6"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "epochs = 20\n",
        "train_samples_steps = len(X_train) // batch_size\n",
        "val_samples_steps = len(X_test) // batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "R-6UM7icZjT2"
      },
      "outputs": [],
      "source": [
        "# generate train and test datra\n",
        "train_gen = generate_batch(X_train, y_train, batch_size = batch_size)\n",
        "test_gen = generate_batch(X_test, y_test, batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "EgIsnJbTZjOC"
      },
      "outputs": [],
      "source": [
        "# Defining a helper function to save the model after each epoch\n",
        "# in which the loss decreases\n",
        "filepath = project_path+'NMT_model_enc_dec.h5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "# Defining a helper function to reduce the learning rate each time\n",
        "# the learning plateaus\n",
        "reduce_alpha = ReduceLROnPlateau(monitor ='val_loss', factor = 0.2,patience = 1, min_lr = 0.001)\n",
        "# stop traning if there increase in loss\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
        "callbacks = [checkpoint, es, reduce_alpha]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhZlEqPNL7aG",
        "outputId": "c1d3815f-a8c3-420e-8d05-4eaf5bcb88db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "from multiprocessing import cpu_count\n",
        "\n",
        "# Get the number of CPU cores available\n",
        "num_cores = cpu_count()\n",
        "num_cores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC2EYkwkZjJG",
        "outputId": "08d57fc2-b5cf-4900-a6fa-508ab5e47188"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-483c85a063ef>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator = train_gen,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 6.6499 - acc: 0.2111\n",
            "Epoch 1: val_loss improved from inf to 6.08324, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 857s 774ms/step - loss: 6.6499 - acc: 0.2111 - val_loss: 6.0832 - val_acc: 0.2269 - lr: 0.0010\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1096/1096 [==============================] - ETA: 0s - loss: 5.8934 - acc: 0.2334\n",
            "Epoch 2: val_loss improved from 6.08324 to 5.71824, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 846s 772ms/step - loss: 5.8934 - acc: 0.2334 - val_loss: 5.7182 - val_acc: 0.2478 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 5.5984 - acc: 0.2600\n",
            "Epoch 3: val_loss improved from 5.71824 to 5.52233, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 846s 772ms/step - loss: 5.5984 - acc: 0.2600 - val_loss: 5.5223 - val_acc: 0.2729 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 5.4040 - acc: 0.2944\n",
            "Epoch 4: val_loss improved from 5.52233 to 5.32343, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 851s 777ms/step - loss: 5.4040 - acc: 0.2944 - val_loss: 5.3234 - val_acc: 0.3108 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 5.2115 - acc: 0.3214\n",
            "Epoch 5: val_loss improved from 5.32343 to 5.15663, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 851s 776ms/step - loss: 5.2115 - acc: 0.3214 - val_loss: 5.1566 - val_acc: 0.3295 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 5.0544 - acc: 0.3392\n",
            "Epoch 6: val_loss improved from 5.15663 to 5.01938, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 838s 765ms/step - loss: 5.0544 - acc: 0.3392 - val_loss: 5.0194 - val_acc: 0.3472 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 4.9153 - acc: 0.3543\n",
            "Epoch 7: val_loss improved from 5.01938 to 4.90065, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 842s 768ms/step - loss: 4.9153 - acc: 0.3543 - val_loss: 4.9007 - val_acc: 0.3578 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 4.8017 - acc: 0.3639\n",
            "Epoch 8: val_loss improved from 4.90065 to 4.80660, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 838s 764ms/step - loss: 4.8017 - acc: 0.3639 - val_loss: 4.8066 - val_acc: 0.3649 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 4.6963 - acc: 0.3741\n",
            "Epoch 9: val_loss improved from 4.80660 to 4.71188, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 827s 755ms/step - loss: 4.6963 - acc: 0.3741 - val_loss: 4.7119 - val_acc: 0.3747 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 4.5895 - acc: 0.3856\n",
            "Epoch 10: val_loss improved from 4.71188 to 4.61334, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 827s 755ms/step - loss: 4.5895 - acc: 0.3856 - val_loss: 4.6133 - val_acc: 0.3854 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 4.4873 - acc: 0.3963\n",
            "Epoch 11: val_loss improved from 4.61334 to 4.52745, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 828s 756ms/step - loss: 4.4873 - acc: 0.3963 - val_loss: 4.5275 - val_acc: 0.3945 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 4.3939 - acc: 0.4061\n",
            "Epoch 12: val_loss improved from 4.52745 to 4.44545, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 827s 755ms/step - loss: 4.3939 - acc: 0.4061 - val_loss: 4.4455 - val_acc: 0.4037 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 4.3038 - acc: 0.4152\n",
            "Epoch 13: val_loss improved from 4.44545 to 4.36676, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 831s 758ms/step - loss: 4.3038 - acc: 0.4152 - val_loss: 4.3668 - val_acc: 0.4102 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 4.2157 - acc: 0.4242\n",
            "Epoch 14: val_loss improved from 4.36676 to 4.29856, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 828s 755ms/step - loss: 4.2157 - acc: 0.4242 - val_loss: 4.2986 - val_acc: 0.4169 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 4.1359 - acc: 0.4327\n",
            "Epoch 15: val_loss improved from 4.29856 to 4.22760, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 832s 759ms/step - loss: 4.1359 - acc: 0.4327 - val_loss: 4.2276 - val_acc: 0.4245 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 4.0615 - acc: 0.4409\n",
            "Epoch 16: val_loss improved from 4.22760 to 4.17245, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 841s 767ms/step - loss: 4.0615 - acc: 0.4409 - val_loss: 4.1724 - val_acc: 0.4306 - lr: 0.0010\n",
            "Epoch 17/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.9899 - acc: 0.4488\n",
            "Epoch 17: val_loss improved from 4.17245 to 4.10731, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 840s 766ms/step - loss: 3.9899 - acc: 0.4488 - val_loss: 4.1073 - val_acc: 0.4376 - lr: 0.0010\n",
            "Epoch 18/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.9200 - acc: 0.4566\n",
            "Epoch 18: val_loss improved from 4.10731 to 4.05815, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 840s 767ms/step - loss: 3.9200 - acc: 0.4566 - val_loss: 4.0582 - val_acc: 0.4428 - lr: 0.0010\n",
            "Epoch 19/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.8500 - acc: 0.4641\n",
            "Epoch 19: val_loss improved from 4.05815 to 3.99705, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 841s 768ms/step - loss: 3.8500 - acc: 0.4641 - val_loss: 3.9970 - val_acc: 0.4490 - lr: 0.0010\n",
            "Epoch 20/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.7824 - acc: 0.4714\n",
            "Epoch 20: val_loss improved from 3.99705 to 3.94965, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 843s 769ms/step - loss: 3.7824 - acc: 0.4714 - val_loss: 3.9496 - val_acc: 0.4538 - lr: 0.0010\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bb0b84f12d0>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # train the model\n",
        "model.fit_generator(generator = train_gen,\n",
        "                    steps_per_epoch = train_samples_steps,\n",
        "                    epochs=epochs,\n",
        "                    validation_data = test_gen,\n",
        "                    validation_steps = val_samples_steps,callbacks = callbacks\n",
        "                  )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdH8TK9xoDI7",
        "outputId": "f0cb36f0-a31d-4ae4-c61c-865bb0573125"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-044401d85895>:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator = train_gen,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.7359 - acc: 0.4760\n",
            "Epoch 1: val_loss improved from inf to 3.74508, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1096/1096 [==============================] - 870s 794ms/step - loss: 3.7359 - acc: 0.4760 - val_loss: 3.7451 - val_acc: 0.4735 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.6670 - acc: 0.4832\n",
            "Epoch 2: val_loss improved from 3.74508 to 3.70516, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 866s 790ms/step - loss: 3.6670 - acc: 0.4832 - val_loss: 3.7052 - val_acc: 0.4774 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.6013 - acc: 0.4902\n",
            "Epoch 3: val_loss improved from 3.70516 to 3.66775, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 870s 794ms/step - loss: 3.6013 - acc: 0.4902 - val_loss: 3.6678 - val_acc: 0.4813 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.5386 - acc: 0.4968\n",
            "Epoch 4: val_loss improved from 3.66775 to 3.62273, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 866s 790ms/step - loss: 3.5386 - acc: 0.4968 - val_loss: 3.6227 - val_acc: 0.4862 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.4788 - acc: 0.5031\n",
            "Epoch 5: val_loss improved from 3.62273 to 3.58788, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 853s 778ms/step - loss: 3.4788 - acc: 0.5031 - val_loss: 3.5879 - val_acc: 0.4901 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.4203 - acc: 0.5094\n",
            "Epoch 6: val_loss improved from 3.58788 to 3.54672, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 843s 769ms/step - loss: 3.4203 - acc: 0.5094 - val_loss: 3.5467 - val_acc: 0.4939 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.3627 - acc: 0.5156\n",
            "Epoch 7: val_loss improved from 3.54672 to 3.51113, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 842s 769ms/step - loss: 3.3627 - acc: 0.5156 - val_loss: 3.5111 - val_acc: 0.4975 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.3057 - acc: 0.5216\n",
            "Epoch 8: val_loss improved from 3.51113 to 3.46489, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 844s 770ms/step - loss: 3.3057 - acc: 0.5216 - val_loss: 3.4649 - val_acc: 0.5019 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.2502 - acc: 0.5277\n",
            "Epoch 9: val_loss improved from 3.46489 to 3.42313, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 843s 769ms/step - loss: 3.2502 - acc: 0.5277 - val_loss: 3.4231 - val_acc: 0.5057 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.1969 - acc: 0.5333\n",
            "Epoch 10: val_loss improved from 3.42313 to 3.39161, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 842s 768ms/step - loss: 3.1969 - acc: 0.5333 - val_loss: 3.3916 - val_acc: 0.5084 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.1447 - acc: 0.5388\n",
            "Epoch 11: val_loss improved from 3.39161 to 3.35174, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 843s 769ms/step - loss: 3.1447 - acc: 0.5388 - val_loss: 3.3517 - val_acc: 0.5130 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.0923 - acc: 0.5444\n",
            "Epoch 12: val_loss improved from 3.35174 to 3.31144, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 841s 767ms/step - loss: 3.0923 - acc: 0.5444 - val_loss: 3.3114 - val_acc: 0.5175 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 3.0394 - acc: 0.5500\n",
            "Epoch 13: val_loss improved from 3.31144 to 3.27446, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 839s 765ms/step - loss: 3.0394 - acc: 0.5500 - val_loss: 3.2745 - val_acc: 0.5214 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.9887 - acc: 0.5555\n",
            "Epoch 14: val_loss improved from 3.27446 to 3.23903, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 837s 764ms/step - loss: 2.9887 - acc: 0.5555 - val_loss: 3.2390 - val_acc: 0.5258 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.9399 - acc: 0.5607\n",
            "Epoch 15: val_loss improved from 3.23903 to 3.19812, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 838s 764ms/step - loss: 2.9399 - acc: 0.5607 - val_loss: 3.1981 - val_acc: 0.5301 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.8935 - acc: 0.5656\n",
            "Epoch 16: val_loss improved from 3.19812 to 3.17317, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 851s 777ms/step - loss: 2.8935 - acc: 0.5656 - val_loss: 3.1732 - val_acc: 0.5331 - lr: 0.0010\n",
            "Epoch 17/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.8483 - acc: 0.5704\n",
            "Epoch 17: val_loss improved from 3.17317 to 3.14245, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 850s 775ms/step - loss: 2.8483 - acc: 0.5704 - val_loss: 3.1425 - val_acc: 0.5350 - lr: 0.0010\n",
            "Epoch 18/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.8045 - acc: 0.5752\n",
            "Epoch 18: val_loss improved from 3.14245 to 3.11400, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 852s 777ms/step - loss: 2.8045 - acc: 0.5752 - val_loss: 3.1140 - val_acc: 0.5367 - lr: 0.0010\n",
            "Epoch 19/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.7620 - acc: 0.5800\n",
            "Epoch 19: val_loss improved from 3.11400 to 3.08169, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 863s 787ms/step - loss: 2.7620 - acc: 0.5800 - val_loss: 3.0817 - val_acc: 0.5412 - lr: 0.0010\n",
            "Epoch 20/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.7209 - acc: 0.5849\n",
            "Epoch 20: val_loss improved from 3.08169 to 3.05622, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 856s 781ms/step - loss: 2.7209 - acc: 0.5849 - val_loss: 3.0562 - val_acc: 0.5444 - lr: 0.0010\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c8c08191690>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# prompt: train additional 20 epochs from last check point\n",
        "\n",
        "# Load the saved model\n",
        "model.load_weights(filepath)\n",
        "\n",
        "# Train the model for additional 20 epochs\n",
        "model.fit_generator(generator = train_gen,\n",
        "                    steps_per_epoch = train_samples_steps,\n",
        "                    epochs=20,\n",
        "                    validation_data = test_gen,\n",
        "                    validation_steps = val_samples_steps,callbacks = callbacks\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pNc5yMDvuwA",
        "outputId": "a7d157d8-2053-4952-a190-7de6f2e8fc3f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-8f1f96697528>:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator = train_gen,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.4369 - acc: 0.6161\n",
            "Epoch 1: val_loss did not improve from 2.49460\n",
            "1096/1096 [==============================] - 899s 820ms/step - loss: 2.4369 - acc: 0.6161 - val_loss: 2.5002 - val_acc: 0.6075 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.3985 - acc: 0.6209\n",
            "Epoch 2: val_loss did not improve from 2.49460\n",
            "1096/1096 [==============================] - 899s 820ms/step - loss: 2.3985 - acc: 0.6209 - val_loss: 2.4948 - val_acc: 0.6083 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.3628 - acc: 0.6249\n",
            "Epoch 3: val_loss improved from 2.49460 to 2.48566, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 902s 823ms/step - loss: 2.3628 - acc: 0.6249 - val_loss: 2.4857 - val_acc: 0.6092 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.3282 - acc: 0.6292\n",
            "Epoch 4: val_loss improved from 2.48566 to 2.47802, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 903s 824ms/step - loss: 2.3282 - acc: 0.6292 - val_loss: 2.4780 - val_acc: 0.6108 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.2938 - acc: 0.6336\n",
            "Epoch 5: val_loss improved from 2.47802 to 2.46873, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 901s 822ms/step - loss: 2.2938 - acc: 0.6336 - val_loss: 2.4687 - val_acc: 0.6116 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.2611 - acc: 0.6372\n",
            "Epoch 6: val_loss improved from 2.46873 to 2.45516, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 880s 803ms/step - loss: 2.2611 - acc: 0.6372 - val_loss: 2.4552 - val_acc: 0.6118 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.2290 - acc: 0.6412\n",
            "Epoch 7: val_loss improved from 2.45516 to 2.44685, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 877s 800ms/step - loss: 2.2290 - acc: 0.6412 - val_loss: 2.4469 - val_acc: 0.6122 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.1975 - acc: 0.6451\n",
            "Epoch 8: val_loss improved from 2.44685 to 2.43812, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 877s 800ms/step - loss: 2.1975 - acc: 0.6451 - val_loss: 2.4381 - val_acc: 0.6129 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.1666 - acc: 0.6486\n",
            "Epoch 9: val_loss improved from 2.43812 to 2.42323, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 877s 800ms/step - loss: 2.1666 - acc: 0.6486 - val_loss: 2.4232 - val_acc: 0.6148 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.1362 - acc: 0.6524\n",
            "Epoch 10: val_loss improved from 2.42323 to 2.41315, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 878s 802ms/step - loss: 2.1362 - acc: 0.6524 - val_loss: 2.4131 - val_acc: 0.6160 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.1068 - acc: 0.6559\n",
            "Epoch 11: val_loss improved from 2.41315 to 2.40375, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 878s 801ms/step - loss: 2.1068 - acc: 0.6559 - val_loss: 2.4037 - val_acc: 0.6165 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.0781 - acc: 0.6592\n",
            "Epoch 12: val_loss improved from 2.40375 to 2.40125, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 879s 802ms/step - loss: 2.0781 - acc: 0.6592 - val_loss: 2.4012 - val_acc: 0.6171 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.0499 - acc: 0.6623\n",
            "Epoch 13: val_loss improved from 2.40125 to 2.38262, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 874s 798ms/step - loss: 2.0499 - acc: 0.6623 - val_loss: 2.3826 - val_acc: 0.6194 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 2.0227 - acc: 0.6657\n",
            "Epoch 14: val_loss improved from 2.38262 to 2.36986, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 876s 800ms/step - loss: 2.0227 - acc: 0.6657 - val_loss: 2.3699 - val_acc: 0.6216 - lr: 0.0010\n",
            "Epoch 15/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.9965 - acc: 0.6689\n",
            "Epoch 15: val_loss improved from 2.36986 to 2.36153, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 878s 801ms/step - loss: 1.9965 - acc: 0.6689 - val_loss: 2.3615 - val_acc: 0.6215 - lr: 0.0010\n",
            "Epoch 16/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.9711 - acc: 0.6721\n",
            "Epoch 16: val_loss improved from 2.36153 to 2.35158, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 877s 800ms/step - loss: 1.9711 - acc: 0.6721 - val_loss: 2.3516 - val_acc: 0.6223 - lr: 0.0010\n",
            "Epoch 17/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.9466 - acc: 0.6751\n",
            "Epoch 17: val_loss improved from 2.35158 to 2.34099, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 876s 800ms/step - loss: 1.9466 - acc: 0.6751 - val_loss: 2.3410 - val_acc: 0.6239 - lr: 0.0010\n",
            "Epoch 18/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.9230 - acc: 0.6779\n",
            "Epoch 18: val_loss improved from 2.34099 to 2.33620, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 846s 772ms/step - loss: 1.9230 - acc: 0.6779 - val_loss: 2.3362 - val_acc: 0.6249 - lr: 0.0010\n",
            "Epoch 19/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.8998 - acc: 0.6806\n",
            "Epoch 19: val_loss improved from 2.33620 to 2.32786, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 838s 765ms/step - loss: 1.8998 - acc: 0.6806 - val_loss: 2.3279 - val_acc: 0.6247 - lr: 0.0010\n",
            "Epoch 20/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.8771 - acc: 0.6836\n",
            "Epoch 20: val_loss improved from 2.32786 to 2.31994, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 837s 764ms/step - loss: 1.8771 - acc: 0.6836 - val_loss: 2.3199 - val_acc: 0.6257 - lr: 0.0010\n",
            "Epoch 21/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.8547 - acc: 0.6864\n",
            "Epoch 21: val_loss improved from 2.31994 to 2.31392, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 836s 762ms/step - loss: 1.8547 - acc: 0.6864 - val_loss: 2.3139 - val_acc: 0.6263 - lr: 0.0010\n",
            "Epoch 22/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.8339 - acc: 0.6890\n",
            "Epoch 22: val_loss improved from 2.31392 to 2.30710, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 836s 763ms/step - loss: 1.8339 - acc: 0.6890 - val_loss: 2.3071 - val_acc: 0.6266 - lr: 0.0010\n",
            "Epoch 23/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.8131 - acc: 0.6917\n",
            "Epoch 23: val_loss improved from 2.30710 to 2.29944, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 842s 769ms/step - loss: 1.8131 - acc: 0.6917 - val_loss: 2.2994 - val_acc: 0.6278 - lr: 0.0010\n",
            "Epoch 24/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.7929 - acc: 0.6943\n",
            "Epoch 24: val_loss improved from 2.29944 to 2.29189, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 839s 766ms/step - loss: 1.7929 - acc: 0.6943 - val_loss: 2.2919 - val_acc: 0.6281 - lr: 0.0010\n",
            "Epoch 25/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.7733 - acc: 0.6968\n",
            "Epoch 25: val_loss improved from 2.29189 to 2.28352, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 836s 763ms/step - loss: 1.7733 - acc: 0.6968 - val_loss: 2.2835 - val_acc: 0.6288 - lr: 0.0010\n",
            "Epoch 26/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.7543 - acc: 0.6993\n",
            "Epoch 26: val_loss improved from 2.28352 to 2.28140, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 837s 764ms/step - loss: 1.7543 - acc: 0.6993 - val_loss: 2.2814 - val_acc: 0.6285 - lr: 0.0010\n",
            "Epoch 27/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.7359 - acc: 0.7014\n",
            "Epoch 27: val_loss did not improve from 2.28140\n",
            "1096/1096 [==============================] - 833s 760ms/step - loss: 1.7359 - acc: 0.7014 - val_loss: 2.2828 - val_acc: 0.6287 - lr: 0.0010\n",
            "Epoch 28/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.7179 - acc: 0.7037\n",
            "Epoch 28: val_loss improved from 2.28140 to 2.27433, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 837s 763ms/step - loss: 1.7179 - acc: 0.7037 - val_loss: 2.2743 - val_acc: 0.6300 - lr: 0.0010\n",
            "Epoch 29/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.7002 - acc: 0.7060\n",
            "Epoch 29: val_loss improved from 2.27433 to 2.26644, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 833s 760ms/step - loss: 1.7002 - acc: 0.7060 - val_loss: 2.2664 - val_acc: 0.6312 - lr: 0.0010\n",
            "Epoch 30/30\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.6828 - acc: 0.7082\n",
            "Epoch 30: val_loss improved from 2.26644 to 2.25843, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n",
            "1096/1096 [==============================] - 835s 762ms/step - loss: 1.6828 - acc: 0.7082 - val_loss: 2.2584 - val_acc: 0.6324 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ebb1c0f2f50>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Load the saved model\n",
        "model.load_weights(filepath)\n",
        "\n",
        "# Train the model for additional 20 epochs\n",
        "model.fit_generator(generator = train_gen,\n",
        "                    steps_per_epoch = train_samples_steps,\n",
        "                    epochs=30,\n",
        "                    validation_data = test_gen,\n",
        "                    validation_steps = val_samples_steps,callbacks = callbacks\n",
        "                  )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "model.load_weights(filepath)\n",
        "\n",
        "# Train the model for additional 20 epochs\n",
        "model.fit_generator(generator = train_gen,\n",
        "                    steps_per_epoch = train_samples_steps,\n",
        "                    epochs=20,\n",
        "                    validation_data = test_gen,\n",
        "                    validation_steps = val_samples_steps,callbacks = callbacks\n",
        "                  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXixt2PzSQoq",
        "outputId": "4a168bb4-9076-41eb-8d4b-f6929cae4d0b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-a0ac473dfc10>:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator = train_gen,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.7128 - acc: 0.7034\n",
            "Epoch 1: val_loss improved from inf to 1.71083, saving model to /content/drive/MyDrive/transformertranslator/NMT_model_enc_dec.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1096/1096 [==============================] - 1074s 969ms/step - loss: 1.7128 - acc: 0.7034 - val_loss: 1.7108 - val_acc: 0.7016 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.6869 - acc: 0.7075\n",
            "Epoch 2: val_loss did not improve from 1.71083\n",
            "1096/1096 [==============================] - 1054s 961ms/step - loss: 1.6869 - acc: 0.7075 - val_loss: 1.7312 - val_acc: 0.6979 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "1096/1096 [==============================] - ETA: 0s - loss: 1.6652 - acc: 0.7104\n",
            "Epoch 3: val_loss did not improve from 1.71083\n",
            "1096/1096 [==============================] - 1046s 954ms/step - loss: 1.6652 - acc: 0.7104 - val_loss: 1.7460 - val_acc: 0.6945 - lr: 0.0010\n",
            "Epoch 3: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ba2203ad930>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------Model Training Completed-------"
      ],
      "metadata": {
        "id": "HRhkGiWH4cX8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgm3iXAJZ1VO"
      },
      "source": [
        "Inference Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "AuUrOBTYZjFm"
      },
      "outputs": [],
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8GT1hQPgiFv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch7pSi5zZ4IY"
      },
      "source": [
        "Decode sample sequeces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BRcs7yXDZjB1"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZwIl65tZ_Cu"
      },
      "source": [
        "Evaluation on Train Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrgmb3huZ94i",
        "outputId": "3cddb36b-64e7-4371-8893-dff97dfe934e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Input English sentence: we liked each other\n",
            "Actual Telugu Translation:  మేము ఒకరినొకరు ఇష్టపడ్డాము \n",
            "Predicted Telugu Translation:  మేము ఒకరినొకరు బాగా కనుగొన్నాము \n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Input English sentence: tom said he could not walk\n",
            "Actual Telugu Translation:  టామ్ తాను నడవలేనని చెప్పాడు \n",
            "Predicted Telugu Translation:  టామ్ తాను డ్రైవ్ చేయకూడదని చెప్పాడు \n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Input English sentence: i did not think i would be late\n",
            "Actual Telugu Translation:  నేను ఆలస్యం అవుతాను అని అనుకోలేదు \n",
            "Predicted Telugu Translation:  నేను ఆలస్యం అవుతాను అని అనుకోలేదు \n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Input English sentence: we had a bad day\n",
            "Actual Telugu Translation:  మాకు చెడ్డ రోజు వచ్చింది \n",
            "Predicted Telugu Translation:  మాకు చెడ్డ రోజు వచ్చింది \n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Input English sentence: i think i should let tom leave\n",
            "Actual Telugu Translation:  నేను టామ్‌ను వదిలి వెళ్ళనివ్వాలని అనుకుంటున్నాను \n",
            "Predicted Telugu Translation:  నేను టామ్‌ను వదిలి వెళ్ళమని అడగాలనుకుంటున్నాను \n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Input English sentence: your parents are here to pick you up\n",
            "Actual Telugu Translation:  మిమ్మల్ని తీసుకోవడానికి మీ తల్లిదండ్రులు ఇక్కడ ఉన్నారు \n",
            "Predicted Telugu Translation:  మీ తల్లిదండ్రులు ఇక్కడ ఉన్నందుకు మిమ్మల్ని ఎవరైనా ఉన్\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Input English sentence: what are you interested in\n",
            "Actual Telugu Translation:  మీరు ఏ విషయంలో ఆసక్తిగా ఉన్నారు \n",
            "Predicted Telugu Translation:  మీకు ఏ ఆసక్తి కలిగి ఉన్నాడు \n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Input English sentence: we are looking for engineers\n",
            "Actual Telugu Translation:  మేము ఇంజనీర్ల కోసం చూస్తున్నాము \n",
            "Predicted Telugu Translation:  మేము వెతుకుతున్నది మేము కోరుకుంటున్నాము \n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Input English sentence: i had trouble pronouncing his name\n",
            "Actual Telugu Translation:  అతని పేరు ఉచ్చరించడంలో నాకు ఇబ్బంది ఉంది \n",
            "Predicted Telugu Translation:  అతని పేరు నాకు ఇబ్బంది ఇష్టం \n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Input English sentence: who is your favorite hockey player\n",
            "Actual Telugu Translation:  మీకు ఇష్టమైన హాకీ ఆటగాడు ఎవరు \n",
            "Predicted Telugu Translation:  మీకు ఇష్టమైన హాకీ ఆటగాడు ఎవరు \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
        "for k in range(10):\n",
        "    (input_seq, actual_output), _ = next(test_gen)\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('Input English sentence:', X_test[k:k+1].values[0])\n",
        "    print('Actual Telugu Translation:', y_test[k:k+1].values[0][6:-4])\n",
        "    print('Predicted Telugu Translation:', decoded_sentence[:-4])\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: based on this code above, now take user english sentence and translate it to telugu\n",
        "\n",
        "import numpy as np\n",
        "def translate_user_input(input_sentence):\n",
        "  # Preprocess the input sentence\n",
        "  input_sentence = clean_eng(input_sentence)\n",
        "  # Convert the input sentence to a tokenized sequence\n",
        "  input_seq = np.zeros((1, max_length_src))\n",
        "  for i, word in enumerate(input_sentence.split()):\n",
        "    if word in input_token_index:\n",
        "      input_seq[0, i] = input_token_index[word]\n",
        "  # Translate the input sentence\n",
        "  translated_sentence = decode_sequence(input_seq)\n",
        "  # Print the translated sentence\n",
        "  print('Translated Telugu sentence:', translated_sentence[:-4])\n",
        "\n",
        "# Get user input sentence\n",
        "input_sentence = input(\"Enter an English sentence: \")\n",
        "\n",
        "# Translate the user input sentence\n",
        "translate_user_input(input_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVPdLpcT2YCm",
        "outputId": "ad7f571c-0d33-44ca-f1d6-6ed2b0821584"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter an English sentence: WHO INVENTED THIS?\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Translated Telugu sentence:  ఈ ఎవరు కనుగొన్నారు \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ew9Mbb86pW16"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}