{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8280318,"sourceType":"datasetVersion","datasetId":4917413}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! nvidia-smi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U \"transformers>=4.39.0\"\n!pip install peft bitsandbytes\n!pip install -U \"trl>=0.8.3\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoProcessor, TrainingArguments, LlavaForConditionalGeneration, BitsAndBytesConfig\nfrom trl import SFTTrainer\nfrom peft import LoraConfig","metadata":{"execution":{"iopub.status.busy":"2024-05-01T17:13:01.293473Z","iopub.execute_input":"2024-05-01T17:13:01.293859Z","iopub.status.idle":"2024-05-01T17:13:08.816734Z","shell.execute_reply.started":"2024-05-01T17:13:01.293826Z","shell.execute_reply":"2024-05-01T17:13:08.815743Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-01 17:13:04.395542: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-01 17:13:04.395590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-01 17:13:04.397078: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"quantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_id = \"llava-hf/llava-1.5-7b-hf\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LlavaForConditionalGeneration.from_pretrained(model_id,\n                                                      quantization_config=quantization_config,\n                                                      torch_dtype=torch.float16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LLAVA_CHAT_TEMPLATE = \"\"\"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. {% for message in messages %}{% if message['role'] == 'user' %}USER: {% else %}ASSISTANT: {% endif %}{% for item in message['content'] %}{% if item['type'] == 'text' %}{{ item['text'] }}{% elif item['type'] == 'image' %}<image>{% endif %}{% endfor %}{% if message['role'] == 'user' %} {% else %}{{eos_token}}{% endif %}{% endfor %}\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_id)\ntokenizer.chat_template = LLAVA_CHAT_TEMPLATE\nprocessor = AutoProcessor.from_pretrained(model_id)\nprocessor.tokenizer = tokenizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_folder_path= '/kaggle/input/museum-scraped-data/images_folder/images_folder/'\njson_file_path= '/kaggle/input/museum-scraped-data/training_dataset_final_json.json'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LLavaDataCollator:\n    def __init__(self, processor):\n        self.processor = processor\n\n    def __call__(self, examples):\n        texts = []\n        images = []\n\n        for example in examples:\n            messages = example[\"messages\"]\n            text = self.processor.tokenizer.apply_chat_template(\n                messages, tokenize=False, add_generation_prompt=False\n            )\n            texts.append(text)\n\n\n            image_path = image_folder_path + example[\"images\"][0]\n\n            images.append(Image.open(image_path))\n\n\n        batch = self.processor(texts, images, return_tensors=\"pt\", padding=True)\n\n        labels = batch[\"input_ids\"].clone()\n        if self.processor.tokenizer.pad_token_id is not None:\n            labels[labels == self.processor.tokenizer.pad_token_id] = -100\n        batch[\"labels\"] = labels\n\n        return batch\n\ndata_collator = LLavaDataCollator(processor)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n# Open the JSON file\nwith open(json_file_path, 'r') as json_file:\n    # Load the JSON data\n    data = json.load(json_file)\n\ntrain_dataset = data[:100]\neval_dataset = data[100:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\n\n#display first and last 5 training dataset images\nimages = [Image.open(image_folder_path + example[\"images\"][0]) for example in train_dataset]\n\nfirst_five_images = images[:5]\nlast_five_images = images[-5:]\n\nfig, axes = plt.subplots(2, 5, figsize=(15, 6))\n\nfor i, ax in enumerate(axes.flat):\n    if i < 5:\n        ax.imshow(first_five_images[i])\n        ax.axis(\"off\")\n    else:\n        ax.imshow(last_five_images[i - 5])\n        ax.axis(\"off\")\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training_args = TrainingArguments(\n#     output_dir=\"llava-1.5-7b-hf-ft-mix-vsft\",\n#     report_to=\"tensorboard\",\n#     learning_rate=1.4e-5,\n#     per_device_train_batch_size=2,\n#     gradient_accumulation_steps=1,\n#     logging_steps=5,\n#     num_train_epochs=1,\n#     push_to_hub=True,\n#     gradient_checkpointing=True,\n#     remove_unused_columns=False,\n#     fp16=True,\n#     bf16=False\n# )\ntraining_args = TrainingArguments(\n    output_dir=\"llava-1.5-7b-hf-ft-mix-vsft\",\n    report_to=\"tensorboard\",\n    learning_rate=5e-5,\n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=1,\n    logging_steps=5,\n    num_train_epochs=10,\n    push_to_hub=True,\n    gradient_checkpointing=True,\n    remove_unused_columns=False,\n    fp16=True,\n    bf16=False\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=64,\n    lora_alpha=16,\n    target_modules=\"all-linear\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install huggingface_hub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-05-01T17:29:38.123762Z","iopub.execute_input":"2024-05-01T17:29:38.124569Z","iopub.status.idle":"2024-05-01T17:29:38.151972Z","shell.execute_reply.started":"2024-05-01T17:29:38.124534Z","shell.execute_reply":"2024-05-01T17:29:38.151013Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c2d6650ea4f4739b59171ddf128fe18"}},"metadata":{}}]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    peft_config=lora_config,\n    dataset_text_field=\"text\",  # need a dummy field\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    dataset_kwargs={\"skip_prepare_dataset\": True},\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%reload_ext tensorboard","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir /content/llava-1.5-7b-hf-ft-mix-vsft","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Inferenceing","metadata":{}},{"cell_type":"code","source":"!pip install -q -U peft","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import PeftModel","metadata":{"execution":{"iopub.status.busy":"2024-05-01T17:13:53.960774Z","iopub.execute_input":"2024-05-01T17:13:53.961473Z","iopub.status.idle":"2024-05-01T17:13:53.966488Z","shell.execute_reply.started":"2024-05-01T17:13:53.961440Z","shell.execute_reply":"2024-05-01T17:13:53.965516Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install -i https://pypi.org/simple/ bitsandbytes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install accelerate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import LlavaForConditionalGeneration, BitsAndBytesConfig","metadata":{"execution":{"iopub.status.busy":"2024-05-01T17:14:04.897705Z","iopub.execute_input":"2024-05-01T17:14:04.898095Z","iopub.status.idle":"2024-05-01T17:14:04.902411Z","shell.execute_reply.started":"2024-05-01T17:14:04.898065Z","shell.execute_reply":"2024-05-01T17:14:04.901460Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model_id = \"llava-hf/llava-1.5-7b-hf\"","metadata":{"execution":{"iopub.status.busy":"2024-05-01T17:14:16.552034Z","iopub.execute_input":"2024-05-01T17:14:16.552739Z","iopub.status.idle":"2024-05-01T17:14:16.556912Z","shell.execute_reply.started":"2024-05-01T17:14:16.552705Z","shell.execute_reply":"2024-05-01T17:14:16.555996Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"quantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-01T17:14:25.237826Z","iopub.execute_input":"2024-05-01T17:14:25.238217Z","iopub.status.idle":"2024-05-01T17:14:25.243952Z","shell.execute_reply.started":"2024-05-01T17:14:25.238188Z","shell.execute_reply":"2024-05-01T17:14:25.243045Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"base_model = LlavaForConditionalGeneration.from_pretrained(model_id,\n                                                      quantization_config=quantization_config,\n                                                      torch_dtype=torch.float16)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T17:14:39.137143Z","iopub.execute_input":"2024-05-01T17:14:39.137813Z","iopub.status.idle":"2024-05-01T17:16:17.188731Z","shell.execute_reply.started":"2024-05-01T17:14:39.137782Z","shell.execute_reply":"2024-05-01T17:16:17.187915Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:103: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect\n  warnings.warn(\n`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/70.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40f6d04966c84d1291b7bbbbf2702acc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4fdd263d8004c29bde112dcd7012ff3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5800002798ec43309a10f4917a82200d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30f7b360c27e4b7d9cff6c94e801a0ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.18G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e579861d21d47f88e797ddd6899e41a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08816952b79447b0ad26a32503e13d33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/141 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff8caff49852429887f61b714adfb969"}},"metadata":{}}]},{"cell_type":"code","source":"# Load the PEFT Lora model (adapter)\npeft_lora_adapter_path = \"GURU369/llava-1.5-7b-hf-ft-mix-vsft\"\npeft_lora_adapter = PeftModel.from_pretrained(base_model,peft_lora_adapter_path, adapter_name=\"lora_adapter\")\n\n# Merge the adapters into the base model\nbase_model.load_adapter(peft_lora_adapter_path, adapter_name=\"lora_adapter\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-01T17:18:52.561344Z","iopub.execute_input":"2024-05-01T17:18:52.562366Z","iopub.status.idle":"2024-05-01T17:19:33.360843Z","shell.execute_reply.started":"2024-05-01T17:18:52.562332Z","shell.execute_reply":"2024-05-01T17:19:33.360011Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/927 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac075f4a4fc646ce8f0c9ba3409efe72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/1.29G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f782c7f0b17f459194a8aa6b5345faef"}},"metadata":{}}]},{"cell_type":"code","source":"base_model.push_to_hub(\"GURU369/llava-1.5-7b-hf-ft-merged\",token=True, safe_serialization=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T17:29:59.708752Z","iopub.execute_input":"2024-05-01T17:29:59.709172Z","iopub.status.idle":"2024-05-01T17:30:31.929223Z","shell.execute_reply.started":"2024-05-01T17:29:59.709131Z","shell.execute_reply":"2024-05-01T17:30:31.928017Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85b56b2fc8944b41ba0c94ff3f096f82"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/GURU369/llava-1.5-7b-hf-ft-merged/commit/87b316ac39bf2df6b8ef529d327958b7bcef34bf', commit_message='Upload LlavaForConditionalGeneration', commit_description='', oid='87b316ac39bf2df6b8ef529d327958b7bcef34bf', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]}]}